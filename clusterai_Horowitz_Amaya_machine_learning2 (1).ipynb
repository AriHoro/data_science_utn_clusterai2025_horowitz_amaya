{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiltoj14EWNf",
        "outputId": "3532db66-b2a2-4eed-ca00-ce2ff25ee2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.3/127.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mljar-supervised (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mljar-scikit-plot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Celda 1: instalación (solo se corre UNA vez, antes de reiniciar)\n",
        "\n",
        "!pip install -q \"numpy==1.26.4\" mljar-supervised\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RZhAQPTBlLN",
        "outputId": "f8de7988-262d-403f-cae5-6b61cb92c0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (45211, 17)\n",
            "    Age           Job Marital Status  Education Credit  Balance (euros)  \\\n",
            "0  58.0           NaN            NaN        NaN     no           2143.0   \n",
            "1  44.0    technician         single  secondary     no              NaN   \n",
            "2  33.0  entrepreneur            NaN  secondary     no              2.0   \n",
            "3  47.0           NaN        married    unknown     no           1506.0   \n",
            "4  33.0       unknown         single    unknown    NaN              1.0   \n",
            "\n",
            "  Housing Loan Personal Loan  Contact  Last Contact Day Last Contact Month  \\\n",
            "0          yes           NaN  unknown                 5                may   \n",
            "1          yes            no  unknown                 5                may   \n",
            "2          yes           yes  unknown                 5                may   \n",
            "3          NaN            no  unknown                 5                may   \n",
            "4           no            no  unknown                 5                may   \n",
            "\n",
            "   Last Contact Duration  Campaign  Pdays  Previous Poutcome  Subscription  \n",
            "0                  261.0         1   -1.0         0  unknown             0  \n",
            "1                  151.0         1   -1.0         0  unknown             0  \n",
            "2                   76.0         1    NaN         0  unknown             0  \n",
            "3                   92.0         1   -1.0         0  unknown             0  \n",
            "4                    NaN         1    NaN         0  unknown             0  \n",
            "\n",
            "Columnas del dataset:\n",
            "['Age', 'Job', 'Marital Status', 'Education', 'Credit', 'Balance (euros)', 'Housing Loan', 'Personal Loan', 'Contact', 'Last Contact Day', 'Last Contact Month', 'Last Contact Duration', 'Campaign', 'Pdays', 'Previous', 'Poutcome', 'Subscription']\n",
            "\n",
            "Total registros: 45211\n",
            "Segmento A (sin historial): 36954\n",
            "Segmento B (historial no exitoso): 6746\n",
            "Segmento C (historial exitoso): 1511\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Global_sin_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[11685   292]\n",
            " [ 1014   573]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95     11977\n",
            "           1       0.66      0.36      0.47      1587\n",
            "\n",
            "    accuracy                           0.90     13564\n",
            "   macro avg       0.79      0.67      0.71     13564\n",
            "weighted avg       0.89      0.90      0.89     13564\n",
            "\n",
            "\n",
            "AUC ROC: 0.9091\n",
            "\n",
            "=== Reporte AutoML para Global_sin_PCA ===\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Segmento_A_sin_historial_sin_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[9836  236]\n",
            " [ 687  328]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.96     10072\n",
            "           1       0.58      0.32      0.42      1015\n",
            "\n",
            "    accuracy                           0.92     11087\n",
            "   macro avg       0.76      0.65      0.69     11087\n",
            "weighted avg       0.90      0.92      0.91     11087\n",
            "\n",
            "\n",
            "AUC ROC: 0.906\n",
            "\n",
            "=== Reporte AutoML para Segmento_A_sin_historial_sin_PCA ===\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Segmento_B_historial_no_exitoso_sin_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[1677   69]\n",
            " [ 185   93]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93      1746\n",
            "           1       0.57      0.33      0.42       278\n",
            "\n",
            "    accuracy                           0.87      2024\n",
            "   macro avg       0.74      0.65      0.68      2024\n",
            "weighted avg       0.86      0.87      0.86      2024\n",
            "\n",
            "\n",
            "AUC ROC: 0.8611\n",
            "\n",
            "=== Reporte AutoML para Segmento_B_historial_no_exitoso_sin_PCA ===\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Segmento_C_historial_exitoso_sin_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[ 41 119]\n",
            " [ 29 265]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.26      0.36       160\n",
            "           1       0.69      0.90      0.78       294\n",
            "\n",
            "    accuracy                           0.67       454\n",
            "   macro avg       0.64      0.58      0.57       454\n",
            "weighted avg       0.65      0.67      0.63       454\n",
            "\n",
            "\n",
            "AUC ROC: 0.6808\n",
            "\n",
            "=== Reporte AutoML para Segmento_C_historial_exitoso_sin_PCA ===\n",
            "\n",
            "Shape original (después del preprocesamiento): (45211, 51)\n",
            "Shape después de PCA: (45211, 18)\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Global_con_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[11529   448]\n",
            " [ 1030   557]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94     11977\n",
            "           1       0.55      0.35      0.43      1587\n",
            "\n",
            "    accuracy                           0.89     13564\n",
            "   macro avg       0.74      0.66      0.68     13564\n",
            "weighted avg       0.88      0.89      0.88     13564\n",
            "\n",
            "\n",
            "AUC ROC: 0.8757\n",
            "\n",
            "=== Reporte AutoML para Global_con_PCA ===\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Segmento_A_sin_historial_con_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[9887  185]\n",
            " [ 758  257]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95     10072\n",
            "           1       0.58      0.25      0.35      1015\n",
            "\n",
            "    accuracy                           0.91     11087\n",
            "   macro avg       0.76      0.62      0.65     11087\n",
            "weighted avg       0.90      0.91      0.90     11087\n",
            "\n",
            "\n",
            "AUC ROC: 0.8694\n",
            "\n",
            "=== Reporte AutoML para Segmento_A_sin_historial_con_PCA ===\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Segmento_B_historial_no_exitoso_con_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[1652   94]\n",
            " [ 189   89]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92      1746\n",
            "           1       0.49      0.32      0.39       278\n",
            "\n",
            "    accuracy                           0.86      2024\n",
            "   macro avg       0.69      0.63      0.65      2024\n",
            "weighted avg       0.84      0.86      0.85      2024\n",
            "\n",
            "\n",
            "AUC ROC: 0.83\n",
            "\n",
            "=== Reporte AutoML para Segmento_B_historial_no_exitoso_con_PCA ===\n",
            "\n",
            "################################################################################\n",
            "AUTOML - SEGMENTO: Segmento_C_historial_exitoso_con_PCA\n",
            "################################################################################\n",
            "\n",
            "Matriz de confusión:\n",
            "[[ 66  94]\n",
            " [ 55 239]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.41      0.47       160\n",
            "           1       0.72      0.81      0.76       294\n",
            "\n",
            "    accuracy                           0.67       454\n",
            "   macro avg       0.63      0.61      0.62       454\n",
            "weighted avg       0.66      0.67      0.66       454\n",
            "\n",
            "\n",
            "AUC ROC: 0.684\n",
            "\n",
            "=== Reporte AutoML para Segmento_C_historial_exitoso_con_PCA ===\n",
            "\n",
            "Resumen AUC por caso:\n",
            "                 Caso       AUC\n",
            "0      Global sin PCA  0.909094\n",
            "2  Segmento A sin PCA  0.905955\n",
            "1      Global con PCA  0.875656\n",
            "3  Segmento A con PCA  0.869426\n",
            "4  Segmento B sin PCA  0.861140\n",
            "5  Segmento B con PCA  0.830049\n",
            "7  Segmento C con PCA  0.684014\n",
            "6  Segmento C sin PCA  0.680846\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 0. Imports base + silencio de warnings\n",
        "# ============================\n",
        "\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "# Silenciar warnings molestos de matplotlib (Arial, etc.)\n",
        "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"matplotlib.axes._base\").setLevel(logging.ERROR)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "\n",
        "from supervised.automl import AutoML\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# Imports extra para PCA y preprocesamiento\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# ==================\n",
        "# 1. Carga de datos\n",
        "# ==================\n",
        "\n",
        "DATA_PATH = \"bank_subscription.csv\"   # ajustar si el archivo tiene otro nombre\n",
        "df = pd.read_csv(DATA_PATH, sep=\";\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n",
        "print(\"\\nColumnas del dataset:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 2. Definición de target, features y segmentos\n",
        "# ==========================================\n",
        "\n",
        "# Variable objetivo\n",
        "TARGET_COL = \"Subscription\"\n",
        "\n",
        "# Features (todas menos la target)\n",
        "feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
        "\n",
        "# Columnas numéricas y categóricas (las mismas del EDA)\n",
        "numeric_cols = [\n",
        "    \"Age\",\n",
        "    \"Balance (euros)\",\n",
        "    \"Last Contact Day\",\n",
        "    \"Last Contact Duration\",\n",
        "    \"Campaign\",\n",
        "    \"Pdays\",\n",
        "    \"Previous\",\n",
        "]\n",
        "\n",
        "cat_cols = [\n",
        "    \"Job\",\n",
        "    \"Marital Status\",\n",
        "    \"Education\",\n",
        "    \"Credit\",\n",
        "    \"Housing Loan\",\n",
        "    \"Personal Loan\",\n",
        "    \"Contact\",\n",
        "    \"Last Contact Month\",\n",
        "    \"Poutcome\",\n",
        "]\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[TARGET_COL].copy()\n",
        "\n",
        "# --- Segmentos ---\n",
        "\n",
        "# Definimos \"hubo contacto previo\" como:\n",
        "# Pdays distinto de -1  o Previous > 0\n",
        "pdays_clean = df[\"Pdays\"].fillna(-1)\n",
        "previous_clean = df[\"Previous\"].fillna(0)\n",
        "\n",
        "has_previous_contact = (pdays_clean != -1) | (previous_clean > 0)\n",
        "\n",
        "# Segmento A: sin historial\n",
        "segment_A_mask = ~has_previous_contact\n",
        "\n",
        "# Segmento C: historial exitoso (Poutcome == 'success')\n",
        "segment_C_mask = (df[\"Poutcome\"] == \"success\") & has_previous_contact\n",
        "\n",
        "# Segmento B: historial no exitoso (hubo contacto previo PERO Poutcome != success)\n",
        "segment_B_mask = has_previous_contact & ~segment_C_mask\n",
        "\n",
        "print(\"\\nTotal registros:\", len(df))\n",
        "print(\"Segmento A (sin historial):\", segment_A_mask.sum())\n",
        "print(\"Segmento B (historial no exitoso):\", segment_B_mask.sum())\n",
        "print(\"Segmento C (historial exitoso):\", segment_C_mask.sum())\n",
        "\n",
        "X_A, y_A = X[segment_A_mask], y[segment_A_mask]\n",
        "X_B, y_B = X[segment_B_mask], y[segment_B_mask]\n",
        "X_C, y_C = X[segment_C_mask], y[segment_C_mask]\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 3. Función auxiliar para correr AutoML\n",
        "# ===========================================\n",
        "\n",
        "def run_automl_segment(X_seg, y_seg, segment_name,\n",
        "                       total_time_limit=600,\n",
        "                       random_state=42,\n",
        "                       show_report=True):\n",
        "    \"\"\"\n",
        "    Corre AutoML de mljar-supervised para un segmento dado,\n",
        "    imprime matriz de confusión, classification_report y AUC ROC\n",
        "    y opcionalmente genera el reporte gráfico (leaderboard, curvas, etc.).\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"#\" * 80)\n",
        "    print(f\"AUTOML - SEGMENTO: {segment_name}\")\n",
        "    print(\"#\" * 80)\n",
        "\n",
        "    # Split estratificado\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_seg, y_seg,\n",
        "        test_size=0.3,\n",
        "        random_state=random_state,\n",
        "        stratify=y_seg\n",
        "    )\n",
        "\n",
        "    # AutoML: usamos modo Explain y verbose=0 para que NO imprima logs largos\n",
        "    automl = AutoML(\n",
        "        mode=\"Explain\",          # modo explicativo (rápido y con reportes)\n",
        "        eval_metric=\"auc\",       # métrica principal AUC\n",
        "        total_time_limit=total_time_limit,\n",
        "        random_state=random_state,\n",
        "        results_path=f\"Automl_{segment_name.replace(' ', '_')}\",\n",
        "        verbose=0                # <--- esto evita el texto de entrenamiento\n",
        "    )\n",
        "\n",
        "    # Entrenamiento\n",
        "    automl.fit(X_train, y_train)\n",
        "\n",
        "    # Predicciones con el mejor modelo encontrado\n",
        "    y_pred = automl.predict(X_test)\n",
        "\n",
        "    try:\n",
        "        y_proba = automl.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, y_proba)\n",
        "    except Exception as e:\n",
        "        print(\"No se pudo calcular AUC ROC desde predict_proba:\", e)\n",
        "        y_proba = None\n",
        "        auc = np.nan\n",
        "\n",
        "    print(\"\\nMatriz de confusión:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    print(\"\\nAUC ROC:\", round(auc, 4) if not np.isnan(auc) else \"NA\")\n",
        "\n",
        "    # ===> Aquí se genera el reporte bonito con tablas y gráficos\n",
        "    if show_report:\n",
        "        print(f\"\\n=== Reporte AutoML para {segment_name} ===\")\n",
        "        automl.report()\n",
        "\n",
        "    return {\n",
        "        \"segmento\": segment_name,\n",
        "        \"auc\": auc,\n",
        "        \"automl\": automl\n",
        "    }\n",
        "\n",
        "\n",
        "# =============================================\n",
        "# 4. Experimentos SIN PCA (dataset completo y segmentos)\n",
        "# =============================================\n",
        "\n",
        "# Dataset completo\n",
        "res_global_sin_pca = run_automl_segment(X, y, \"Global_sin_PCA\", total_time_limit=900)\n",
        "\n",
        "# Segmento A - sin historial\n",
        "res_A_sin_pca = run_automl_segment(X_A, y_A, \"Segmento_A_sin_historial_sin_PCA\", total_time_limit=600)\n",
        "\n",
        "# Segmento B - historial no exitoso\n",
        "res_B_sin_pca = run_automl_segment(X_B, y_B, \"Segmento_B_historial_no_exitoso_sin_PCA\", total_time_limit=600)\n",
        "\n",
        "# Segmento C - historial exitoso\n",
        "res_C_sin_pca = run_automl_segment(X_C, y_C, \"Segmento_C_historial_exitoso_sin_PCA\", total_time_limit=300)\n",
        "\n",
        "\n",
        "# ==================================================\n",
        "# 5. Construcción de dataset con PCA (sobre One-Hot)\n",
        "# ==================================================\n",
        "\n",
        "# Preprocesamiento: imputación + escalado + One-Hot\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Ajustamos y transformamos TODO X (dataset completo)\n",
        "X_pre_all = preprocess.fit_transform(X)\n",
        "\n",
        "# Aseguramos densidad para PCA\n",
        "if hasattr(X_pre_all, \"toarray\"):\n",
        "    X_pre_all = X_pre_all.toarray()\n",
        "\n",
        "# PCA manteniendo ~90% de la varianza\n",
        "pca = PCA(n_components=0.9, random_state=42)\n",
        "X_pca_all = pca.fit_transform(X_pre_all)\n",
        "\n",
        "print(\"\\nShape original (después del preprocesamiento):\", X_pre_all.shape)\n",
        "print(\"Shape después de PCA:\", X_pca_all.shape)\n",
        "\n",
        "# DataFrame con componentes principales\n",
        "pca_cols = [f\"PC_{i+1}\" for i in range(X_pca_all.shape[1])]\n",
        "X_pca_df = pd.DataFrame(X_pca_all, columns=pca_cols, index=df.index)\n",
        "\n",
        "# Segmentos pero en el espacio PCA (usamos las mismas máscaras de filas)\n",
        "X_pca_global = X_pca_df\n",
        "X_pca_A = X_pca_df[segment_A_mask]\n",
        "X_pca_B = X_pca_df[segment_B_mask]\n",
        "X_pca_C = X_pca_df[segment_C_mask]\n",
        "\n",
        "\n",
        "# =============================================\n",
        "# 6. Experimentos CON PCA (dataset completo y segmentos)\n",
        "# =============================================\n",
        "\n",
        "# Dataset completo con PCA\n",
        "res_global_con_pca = run_automl_segment(X_pca_global, y, \"Global_con_PCA\", total_time_limit=900)\n",
        "\n",
        "# Segmento A - sin historial, con PCA\n",
        "res_A_con_pca = run_automl_segment(X_pca_A, y_A, \"Segmento_A_sin_historial_con_PCA\", total_time_limit=600)\n",
        "\n",
        "# Segmento B - historial no exitoso, con PCA\n",
        "res_B_con_pca = run_automl_segment(X_pca_B, y_B, \"Segmento_B_historial_no_exitoso_con_PCA\", total_time_limit=600)\n",
        "\n",
        "# Segmento C - historial exitoso, con PCA\n",
        "res_C_con_pca = run_automl_segment(X_pca_C, y_C, \"Segmento_C_historial_exitoso_con_PCA\", total_time_limit=300)\n",
        "\n",
        "\n",
        "# ==================================\n",
        "# 7. Resumen rápido de AUC por caso\n",
        "# ==================================\n",
        "\n",
        "resumen_auc = pd.DataFrame([\n",
        "    {\"Caso\": \"Global sin PCA\",      \"AUC\": res_global_sin_pca[\"auc\"]},\n",
        "    {\"Caso\": \"Global con PCA\",      \"AUC\": res_global_con_pca[\"auc\"]},\n",
        "    {\"Caso\": \"Segmento A sin PCA\",  \"AUC\": res_A_sin_pca[\"auc\"]},\n",
        "    {\"Caso\": \"Segmento A con PCA\",  \"AUC\": res_A_con_pca[\"auc\"]},\n",
        "    {\"Caso\": \"Segmento B sin PCA\",  \"AUC\": res_B_sin_pca[\"auc\"]},\n",
        "    {\"Caso\": \"Segmento B con PCA\",  \"AUC\": res_B_con_pca[\"auc\"]},\n",
        "    {\"Caso\": \"Segmento C sin PCA\",  \"AUC\": res_C_sin_pca[\"auc\"]},\n",
        "    {\"Caso\": \"Segmento C con PCA\",  \"AUC\": res_C_con_pca[\"auc\"]},\n",
        "])\n",
        "\n",
        "print(\"\\nResumen AUC por caso:\")\n",
        "print(resumen_auc.sort_values(\"AUC\", ascending=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}